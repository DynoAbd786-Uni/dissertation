{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66e59d1",
   "metadata": {},
   "source": [
    "# Aneurysm Simulation Velocity Magnitude Analyzer\n",
    "\n",
    "This notebook loads the pre-processed velocity magnitude data from VTK files and corresponding simulation parameters from JSON files. It provides tools for analyzing the flow patterns in aneurysm simulations based on the velocity magnitude field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3621ba13",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# For 3D visualization \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c06229",
   "metadata": {},
   "source": [
    "## Locate and Load Simulation Parameters\n",
    "\n",
    "First, we need to find the simulation parameters in the JSON files stored in the 'parameters' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory where the simulation results are located\n",
    "base_dir = Path('/home/abdua786/code/uni/3/dissertation/dissertation')\n",
    "simulation_folder = base_dir / 'aneurysm_simulation_results'\n",
    "\n",
    "# Check if the simulation folder exists\n",
    "if not simulation_folder.exists():\n",
    "    print(f\"Error: Simulation folder not found at {simulation_folder}\")\n",
    "else:\n",
    "    print(f\"Found simulation folder at: {simulation_folder}\")\n",
    "    \n",
    "    # Define paths to the parameters folder and processed data folder\n",
    "    params_folder = simulation_folder / 'parameters'\n",
    "    processed_data_folder = simulation_folder / 'processed_data' / 'raw_fields'\n",
    "    \n",
    "    # Check if each folder exists\n",
    "    folders_status = {\n",
    "        \"Parameter files\": params_folder.exists(),\n",
    "        \"Processed data\": processed_data_folder.exists()\n",
    "    }\n",
    "    \n",
    "    for folder_type, exists in folders_status.items():\n",
    "        status = \"✓ Found\" if exists else \"✗ Not found\"\n",
    "        print(f\"{status}: {folder_type}\")\n",
    "    \n",
    "    # Get all parameter files\n",
    "    if params_folder.exists():\n",
    "        param_files = list(params_folder.glob('*.json'))\n",
    "        print(f\"\\nFound {len(param_files)} parameter files\")\n",
    "        \n",
    "        # Display some example filenames\n",
    "        if param_files:\n",
    "            print(\"Example parameter files:\")\n",
    "            for file in param_files[:3]:  # Show up to 3 files\n",
    "                print(f\"- {file.name}\")\n",
    "\n",
    "    # Check for processed data files\n",
    "    if processed_data_folder.exists():\n",
    "        npz_files = list(processed_data_folder.glob('*.npz'))\n",
    "        print(f\"\\nFound {len(npz_files)} processed data files\")\n",
    "        \n",
    "        # Display some example filenames\n",
    "        if npz_files:\n",
    "            print(\"Example data files:\")\n",
    "            for file in npz_files[:5]:  # Show up to 5 files\n",
    "                print(f\"- {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0cdf25",
   "metadata": {},
   "source": [
    "## Extract Key Simulation Parameters\n",
    "\n",
    "Now, let's load and parse the parameter files to extract the key simulation parameters such as frames per second (fps), time step (dt), and grid spacing (dx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15d989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters(param_files):\n",
    "    \"\"\"Load and parse parameter files\"\"\"\n",
    "    parameters = {}\n",
    "    \n",
    "    if not param_files:\n",
    "        print(\"No parameter files to load\")\n",
    "        return parameters\n",
    "    \n",
    "    for file_path in param_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                # Use the filename as the key\n",
    "                parameters[file_path.stem] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path.name}: {e}\")\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "# Load the parameters if parameter files were found\n",
    "if 'param_files' in locals() and param_files:\n",
    "    sim_parameters = load_parameters(param_files)\n",
    "    \n",
    "    # Display the parameters in a structured way\n",
    "    if sim_parameters:\n",
    "        print(f\"Loaded {len(sim_parameters)} parameter files successfully\")\n",
    "        \n",
    "        # Display parameters from the first file as an example\n",
    "        first_param_file = next(iter(sim_parameters))\n",
    "        params = sim_parameters[first_param_file]\n",
    "        \n",
    "        print(f\"\\nParameters from {first_param_file}:\")\n",
    "        # Group parameters by category if they follow a standard format\n",
    "        # Otherwise, display the top-level parameters\n",
    "        for key, value in params.items():\n",
    "            # If the value is a dictionary, show it in a compact form\n",
    "            if isinstance(value, dict):\n",
    "                print(f\"- {key}: {len(value)} parameters\")\n",
    "            elif isinstance(value, list) and len(value) > 5:\n",
    "                print(f\"- {key}: list with {len(value)} items\")\n",
    "            else:\n",
    "                print(f\"- {key}: {value}\")\n",
    "else:\n",
    "    print(\"No parameter files available\")\n",
    "    sim_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_parameters(sim_parameters):\n",
    "    \"\"\"Extract the key simulation parameters needed for analysis\"\"\"\n",
    "    # Initialize dictionary for key parameters\n",
    "    key_params = {}\n",
    "    \n",
    "    # Loop through all parameter files\n",
    "    for param_name, params in sim_parameters.items():\n",
    "        key_params[param_name] = {}\n",
    "        \n",
    "        # Extract time step (dt) if available\n",
    "        if 'dt' in params:\n",
    "            key_params[param_name]['dt'] = params['dt']\n",
    "        elif 'time_step' in params:\n",
    "            key_params[param_name]['dt'] = params['time_step']\n",
    "        \n",
    "        # Extract grid spacing (dx) if available\n",
    "        if 'dx' in params:\n",
    "            key_params[param_name]['dx'] = params['dx']\n",
    "        elif 'lattice_spacing' in params:\n",
    "            key_params[param_name]['dx'] = params['lattice_spacing']\n",
    "        \n",
    "        # Extract viscosity\n",
    "        if 'viscosity' in params:\n",
    "            key_params[param_name]['viscosity'] = params['viscosity']\n",
    "        \n",
    "        # Extract domain size\n",
    "        if 'domain_size' in params:\n",
    "            key_params[param_name]['domain_size'] = params['domain_size']\n",
    "        \n",
    "        # Extract total number of time steps\n",
    "        if 'total_timesteps' in params:\n",
    "            key_params[param_name]['total_timesteps'] = params['total_timesteps']\n",
    "        \n",
    "        # Extract frames per second if available or calculate it\n",
    "        if 'fps' in params:\n",
    "            key_params[param_name]['fps'] = params['fps']\n",
    "        elif 'output_frequency' in params and 'dt' in key_params[param_name]:\n",
    "            # Calculate fps = 1 / (dt * output_frequency)\n",
    "            dt = key_params[param_name]['dt']\n",
    "            output_freq = params['output_frequency']\n",
    "            key_params[param_name]['fps'] = 1.0 / (dt * output_freq)\n",
    "        \n",
    "        # Calculate Reynolds number if possible\n",
    "        if all(k in key_params[param_name] for k in ['viscosity', 'dx']) and 'characteristic_velocity' in params:\n",
    "            # Re = (U * L) / nu where U is characteristic velocity, L is characteristic length\n",
    "            u = params['characteristic_velocity']\n",
    "            l = key_params[param_name]['dx'] * params.get('characteristic_length_cells', 1)\n",
    "            nu = key_params[param_name]['viscosity']\n",
    "            key_params[param_name]['reynolds_number'] = (u * l) / nu\n",
    "    \n",
    "    return key_params\n",
    "\n",
    "# Extract key parameters\n",
    "if 'sim_parameters' in locals() and sim_parameters:\n",
    "    key_params = extract_key_parameters(sim_parameters)\n",
    "    \n",
    "    # Display the extracted parameters\n",
    "    if key_params:\n",
    "        print(\"\\nExtracted Key Parameters:\")\n",
    "        for param_name, params in key_params.items():\n",
    "            print(f\"\\nParameters from {param_name}:\")\n",
    "            for key, value in params.items():\n",
    "                print(f\"- {key}: {value}\")\n",
    "    else:\n",
    "        print(\"No key parameters could be extracted\")\n",
    "else:\n",
    "    print(\"No simulation parameters available\")\n",
    "    key_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9134e1",
   "metadata": {},
   "source": [
    "## Load Velocity Magnitude Data\n",
    "\n",
    "Now we'll load the velocity magnitude data from the pre-processed NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10876186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_data(processed_data_folder, field_name='u_magnitude'):\n",
    "    \"\"\"Load processed data for a specific field\"\"\"\n",
    "    # Check if the folder exists\n",
    "    if not processed_data_folder.exists():\n",
    "        print(f\"Error: Processed data folder not found at {processed_data_folder}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Check if the frame mapping file exists\n",
    "    frame_mapping_file = processed_data_folder / 'frame_mapping.npz'\n",
    "    if not frame_mapping_file.exists():\n",
    "        print(f\"Error: Frame mapping file not found at {frame_mapping_file}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Check if the field data file exists\n",
    "    field_data_file = processed_data_folder / f'{field_name}.npz'\n",
    "    if not field_data_file.exists():\n",
    "        print(f\"Error: Field data file not found at {field_data_file}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        # Load frame mapping\n",
    "        frame_mapping = np.load(frame_mapping_file)\n",
    "        frame_numbers = frame_mapping['frame_numbers']\n",
    "        frame_indices = frame_mapping['frame_indices']\n",
    "        \n",
    "        # Load field data\n",
    "        field_data = np.load(field_data_file)['data']\n",
    "        \n",
    "        print(f\"Successfully loaded {field_name} data with shape {field_data.shape}\")\n",
    "        print(f\"Frame mapping contains {len(frame_numbers)} frames\")\n",
    "        \n",
    "        # Create a more convenient mapping\n",
    "        frame_to_index = {frame: idx for frame, idx in zip(frame_numbers, frame_indices)}\n",
    "        \n",
    "        return field_data, frame_to_index\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load velocity magnitude data\n",
    "if 'processed_data_folder' in locals() and processed_data_folder.exists():\n",
    "    velocity_data, frame_to_index = load_processed_data(processed_data_folder, 'u_magnitude')\n",
    "    \n",
    "    if velocity_data is not None:\n",
    "        # Display some basic info about the velocity data\n",
    "        print(f\"\\nVelocity magnitude data:\")\n",
    "        print(f\"- Shape: {velocity_data.shape}\")\n",
    "        print(f\"- Data type: {velocity_data.dtype}\")\n",
    "        print(f\"- Min value: {velocity_data.min()}\")\n",
    "        print(f\"- Max value: {velocity_data.max()}\")\n",
    "        print(f\"- Mean value: {velocity_data.mean()}\")\n",
    "        \n",
    "        # Show frame numbers (first few and last few)\n",
    "        frame_numbers = sorted(frame_to_index.keys())\n",
    "        if len(frame_numbers) > 6:\n",
    "            print(f\"\\nFrame numbers: {frame_numbers[:3]} ... {frame_numbers[-3:]}\")\n",
    "        else:\n",
    "            print(f\"\\nFrame numbers: {frame_numbers}\")\n",
    "else:\n",
    "    print(\"Processed data folder not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_field_data(field_data, dimensions_file=None):\n",
    "    \"\"\"Reshape 1D field data into 2D arrays based on simulation dimensions\"\"\"\n",
    "    # If dimensions file is provided, load it\n",
    "    if dimensions_file is not None and dimensions_file.exists():\n",
    "        try:\n",
    "            dimensions = np.load(dimensions_file)['data']\n",
    "            # Get real dimensions (non-zero)\n",
    "            real_dims = [d for d in dimensions if d > 1]\n",
    "            # The dimensions are cell counts + 1 in VTK\n",
    "            ny, nx = real_dims[1]-1, real_dims[0]-1\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dimensions: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        # Try to infer dimensions from the data shape\n",
    "        # Assuming square domain if dimensions file is not available\n",
    "        if field_data.ndim == 2:\n",
    "            total_cells = field_data.shape[1]\n",
    "            side_length = int(np.sqrt(total_cells))\n",
    "            if side_length**2 == total_cells:\n",
    "                nx, ny = side_length, side_length\n",
    "            else:\n",
    "                print(f\"Cannot infer dimensions from data shape {field_data.shape}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Unexpected data shape: {field_data.shape}\")\n",
    "            return None\n",
    "    \n",
    "    print(f\"Reshaping data to dimensions: ({ny}, {nx})\")\n",
    "    \n",
    "    # Reshape the data\n",
    "    if field_data.ndim == 2:\n",
    "        # Multiple frames (frames, cells)\n",
    "        n_frames = field_data.shape[0]\n",
    "        reshaped_data = np.zeros((n_frames, ny, nx), dtype=field_data.dtype)\n",
    "        \n",
    "        for i in range(n_frames):\n",
    "            try:\n",
    "                # Reshape and apply vertical flip for correct orientation\n",
    "                reshaped_data[i] = np.flipud(field_data[i].reshape(ny, nx))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reshaping frame {i}: {e}\")\n",
    "                return None\n",
    "    else:\n",
    "        # Single frame\n",
    "        try:\n",
    "            reshaped_data = np.flipud(field_data.reshape(ny, nx))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reshaping data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    return reshaped_data\n",
    "\n",
    "# Reshape the velocity data\n",
    "if 'velocity_data' in locals() and velocity_data is not None:\n",
    "    # Check for dimensions file\n",
    "    dimensions_file = processed_data_folder / 'dimensions.npz'\n",
    "    \n",
    "    # Reshape the data\n",
    "    reshaped_velocity = reshape_field_data(velocity_data, dimensions_file)\n",
    "    \n",
    "    if reshaped_velocity is not None:\n",
    "        print(f\"\\nReshaped velocity data:\")\n",
    "        print(f\"- Shape: {reshaped_velocity.shape}\")\n",
    "        \n",
    "        # Convert frame indices to simulation time if we have dt\n",
    "        if 'key_params' in locals() and key_params:\n",
    "            # Get the first parameter set\n",
    "            first_param = next(iter(key_params.values()))\n",
    "            if 'dt' in first_param:\n",
    "                dt = first_param['dt']\n",
    "                # Create time mapping\n",
    "                frame_to_time = {frame: frame * dt for frame in frame_numbers}\n",
    "                print(f\"\\nConverted frames to simulation time using dt = {dt}\")\n",
    "                print(f\"Time range: {frame_to_time[frame_numbers[0]]} to {frame_to_time[frame_numbers[-1]]}\")\n",
    "else:\n",
    "    print(\"No velocity data available for reshaping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b70f8",
   "metadata": {},
   "source": [
    "## Basic Data Visualization\n",
    "\n",
    "Let's create visualizations of the velocity magnitude data at different time points."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
